{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LSTM、GRUによる自然言語処理\n",
    "LSTM、GRUを使って、文書の自動作成を行います。  \n",
    "今回も、江戸川乱歩の「怪人二十面相」を学習データに使い、乱歩風の文章を自動生成します。  \n",
    "以前にSimpleRNNを扱った時と同じように、文章における文字の並びを時系列データと捉えて、次の文字を予測するように訓練します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストデータの前処理\n",
    "今回は、LSTM、GRU共に学習データとして青空文庫の「怪人二十面相」を使います。  \n",
    "最初に、テキストデータに前処理を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字数 110323\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(\"kaijin_nijumenso.txt\", mode=\"r\", encoding=\"utf-8\") as f:  # ファイルの読み込み\n",
    "    text_original = f.read()\n",
    "\n",
    "text = re.sub(\"《[^》]+》\", \"\", text_original) # ルビの削除\n",
    "text = re.sub(\"［[^］]+］\", \"\", text) # 読みの注意の削除\n",
    "text = re.sub(\"[｜ 　]\", \"\", text) # | と全角半角スペースの削除\n",
    "print(\"文字数\", len(text))  # len() で文字列の文字数も取得可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各設定\n",
    "LSTM、GRU共通の各設定です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rnn = 10  # 時系列の数\n",
    "batch_size = 128\n",
    "epochs = 60\n",
    "n_mid = 256  # 中間層のニューロン数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字のベクトル化\n",
    "各文字をone-hot表現で表し、時系列の入力データおよび正解データを作成します。  \n",
    "今回もRNNの最後の時刻の出力のみ利用するので、最後の出力に対応する正解のみ必要になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字数（重複無し） 1249\n",
      "xの形状 (110313, 10, 1249)\n",
      "tの形状 (110313, 1249)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# インデックスと文字で辞書を作成\n",
    "chars = sorted(list(set(text)))  # setで文字の重複をなくし、各文字をリストに格納する\n",
    "print(\"文字数（重複無し）\", len(chars))\n",
    "char_indices = {}  # 文字がキーでインデックスが値\n",
    "for i, char in enumerate(chars):\n",
    "    char_indices[char] = i\n",
    "indices_char = {}  # インデックスがキーで文字が値\n",
    "for i, char in enumerate(chars):\n",
    "    indices_char[i] = char\n",
    " \n",
    "# 時系列データと、それから予測すべき文字を取り出します\n",
    "time_chars = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - n_rnn):\n",
    "    time_chars.append(text[i: i + n_rnn])\n",
    "    next_chars.append(text[i + n_rnn])\n",
    " \n",
    "# 入力と正解をone-hot表現で表します\n",
    "x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool)\n",
    "t = np.zeros((len(time_chars), len(chars)), dtype=np.bool)\n",
    "for i, t_cs in enumerate(time_chars):\n",
    "    t[i, char_indices[next_chars[i]]] = 1  # 正解をone-hot表現で表す\n",
    "    for j, char in enumerate(t_cs):\n",
    "        x[i, j, char_indices[char]] = 1  # 入力をone-hot表現で表す\n",
    "        \n",
    "print(\"xの形状\", x.shape)\n",
    "print(\"tの形状\", t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMモデルの構築\n",
    "Kerasを使ってLSTMを構築します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               1542144   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1249)              320993    \n",
      "=================================================================\n",
      "Total params: 1,863,137\n",
      "Trainable params: 1,863,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, len(chars))))\n",
    "model_lstm.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文書生成用の関数\n",
    "各エポックの終了後、文章を生成するための関数を記述します。  \n",
    "LambdaCallbackを使って、エポック終了時に実行される関数を設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    " \n",
    "def on_epoch_end(epoch, logs):\n",
    "    print(\"エポック: \", epoch)\n",
    "\n",
    "    beta = 5  # 確率分布を調整する定数\n",
    "    prev_text = text[0:n_rnn]  # 入力に使う文字\n",
    "    created_text = prev_text  # 生成されるテキスト\n",
    "    \n",
    "    print(\"シード: \", created_text)\n",
    "\n",
    "    for i in range(400):\n",
    "        # 入力をone-hot表現に\n",
    "        x_pred = np.zeros((1, n_rnn, len(chars)))\n",
    "        for j, char in enumerate(prev_text):\n",
    "            x_pred[0, j, char_indices[char]] = 1\n",
    "        \n",
    "        # 予測を行い、次の文字を得る\n",
    "        y = model.predict(x_pred)\n",
    "        p_power = y[0] ** beta  # 確率分布の調整\n",
    "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power))        \n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        created_text += next_char\n",
    "        prev_text = prev_text[1:] + next_char\n",
    "\n",
    "    print(created_text)\n",
    "    print()\n",
    "\n",
    "# エポック終了後に実行される関数を設定\n",
    "epock_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "構築したLSTMを使って、学習を行います。  \n",
    "fit( )メソッドでコールバックの設定をし、エポック終了後に関数が呼ばれるようにします。  \n",
    "学習には数時間かかるので、時間のない方はエポック数を少なくして実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "862/862 [==============================] - 119s 138ms/step - loss: 4.9966\n",
      "エポック:  0\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町に、そのののを、やのののと、そのです。\n",
      "「のは、あいのは、そののこのです。\n",
      "「いうののうのです。\n",
      "「「、そのです。\n",
      "「ああいうのです。\n",
      "「、そののも、そのです。\n",
      "「は、あののです。\n",
      "「、そうと、そののと、そののとのののは、そののは、そののののに、そののです。\n",
      "「は、あったのです。\n",
      "「のは、おりのものは、そのは、そのです。\n",
      "「そのと、そののと、そうに、そのです。\n",
      "「あ、そのは、、ののののうに、そののです。\n",
      "「の、そのです。\n",
      "「、うのです。\n",
      "「「、そのです。\n",
      "「のか、そのです。\n",
      "「のののです。\n",
      "「十面相のです。\n",
      "「と、そのです。\n",
      "「ののに、あのと、は、とのののののののは、そのです。\n",
      "「そののが、そのです。\n",
      "「のは、そうのです。\n",
      "「のは、そののに、ものいうの二うと、、そののは、そのに、は、そのに、かのです。\n",
      "「「のです。\n",
      "「「、、そのでは、そのです。\n",
      "「は、そのは、そのに、そののは、そのと、その\n",
      "\n",
      "Epoch 2/60\n",
      "862/862 [==============================] - 118s 137ms/step - loss: 4.0368\n",
      "エポック:  1\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町をしているのです。\n",
      "「した。\n",
      "「ありました。\n",
      "「こと、そのです。\n",
      "「ありは、そのです。\n",
      "「は、そのです。\n",
      "「そのは、そのです。\n",
      "「ありは、そのです。\n",
      "「それは、そのです。\n",
      "「そのです。\n",
      "「それは、そのです。\n",
      "「は、そのです。\n",
      "「そのです。\n",
      "「そうに、それをしているというです。\n",
      "「ありました。\n",
      "「そのです。\n",
      "「いったのです。\n",
      "「ありのです。\n",
      "「は、そのです。\n",
      "「二十面相は、そのです。\n",
      "「人のは、そのです。\n",
      "「そのは、それたのです。\n",
      "「そのです。\n",
      "「あ、それは、そのでしたのです。\n",
      "「ました。\n",
      "「そのです。\n",
      "「いるのです。\n",
      "「それは、そのです。\n",
      "「は、それは、そのです。\n",
      "「したのです。\n",
      "「こんは、そのでした。\n",
      "「ありは、そのです。\n",
      "「は、それないと、そのです。\n",
      "「ありました。\n",
      "「そのです。\n",
      "「そうに、そのです。\n",
      "「そのは、それに、そのです。\n",
      "「老人は、そのです。\n",
      "「あいるのです。\n",
      "「ありました。\n",
      "\n",
      "Epoch 3/60\n",
      "862/862 [==============================] - 119s 139ms/step - loss: 3.6384\n",
      "エポック:  2\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町を、そのですから、そのですから、そのです。\n",
      "「あ、それは、そのです。\n",
      "「あ、、そのです。\n",
      "「あ、それは、それから、そのから、そのですから、そのから、そのですが、そのですから、そのです。\n",
      "「あ、それが、そのですから、そのですから、そのですが、そのですから、そのですから、そのですから、そのですから、そのです。\n",
      "「あ、それは、そのです。\n",
      "「あ、それは、そのですから、このです。\n",
      "「し、それは、そのですから、そのですから、そのですから、そのですから、そのから、そのです。\n",
      "「あ、、そのは、そのですから、そのです。\n",
      "「あ、あんなんでは、そのですから、そのですから、そのです。\n",
      "「それは、そのです。\n",
      "「あ、、そのです。\n",
      "「あ、それは、そのです。\n",
      "「あ、それは、それと、そのです。\n",
      "「あ、そうないから、そのです。\n",
      "「あ、それは、そのです。\n",
      "「あ、あ、それは、このです。\n",
      "「あ、、そのは、そのですから、そのです。\n",
      "\n",
      "\n",
      "Epoch 4/60\n",
      "862/862 [==============================] - 121s 140ms/step - loss: 3.3936\n",
      "エポック:  3\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町に、おましたから、そのなんでは、そのです。\n",
      "「あ、それは、それないうないです。\n",
      "「あり、それないうないです。\n",
      "「あ、それは、それないうと、そのなんなから、それから、そのです。\n",
      "「あ、それが、そのです。\n",
      "「あ、それは、それから、そのから、それから、それて、そのです。\n",
      "「あ、それは、それから、そのです。」\n",
      "「それは、それないっていました。\n",
      "「ハハハ……、あるのです。\n",
      "「あ、それは、それは、そのではありません。それて、そのでも、そのほどのです。\n",
      "「あ、それは、それから、それは、そのです。\n",
      "「あ、それは、それから、いっているのです。\n",
      "「あ、されは、そのです。\n",
      "「それは、あのことが、そのです。\n",
      "「それは、それが、そのです。\n",
      "「それは、それから、そのです。\n",
      "「あ、それは、それないうないです。\n",
      "「あ、それは、それには、そのなんでは、それないうのです。\n",
      "「ハハハ……、あるのです。\n",
      "「あ、それは、それないう\n",
      "\n",
      "Epoch 5/60\n",
      "862/862 [==============================] - 121s 140ms/step - loss: 3.2155\n",
      "エポック:  4\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町というのです。\n",
      "「あ、それが、それないうのです。\n",
      "「あ、そのです。\n",
      "「ああ、それが、それに、そのではありません。\n",
      "「ああ、それは、そのでは、その人のです。\n",
      "「ああ、それは、それが、ぼくのように、そのから、そのなんでも、そのなんでもありません。\n",
      "「あ、それは、いうものです。\n",
      "「ああ、それが、そのでも、いうなんだ。」\n",
      "壮二君は、その中に、そのものではないから、そのことが、そのなんというのです。\n",
      "「あ、それは、そうないのです。\n",
      "「あ、それは、そのおというのです。\n",
      "「ああ、それは、そうなんというのです。\n",
      "「ああ、そうなんだ。」\n",
      "「ああ、そのです。\n",
      "「あ、そのです。\n",
      "「ああ、そのです。\n",
      "「あ、それは、そのです。\n",
      "「ああ、それは、そのです。\n",
      "「ああ、それが、そのです。\n",
      "「あ、それは、それないうというのです。\n",
      "「あ、それは、それから、二十面相のというのです。\n",
      "「ああ、それは、そのです。\n",
      "「ああ、それは、\n",
      "\n",
      "Epoch 6/60\n",
      "862/862 [==============================] - 123s 142ms/step - loss: 3.0757\n",
      "エポック:  5\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町には、その中には、この中に、そのです。\n",
      "「ああ、それは、おころにして、そのです。\n",
      "「ああ、あれは、それには、その人のというに、そのです。\n",
      "「あ、それは、これは、そのです。\n",
      "「ああ、それは、このです。\n",
      "「ああ、それはいうないです。\n",
      "「ハハハ……、こんないです。\n",
      "「ああ、それは、そのです。\n",
      "「ああ、それは、それないうには、このなんです。\n",
      "「ハハハ……、二十面相のように、そのです。\n",
      "「ああ、それが、それないのです。\n",
      "「あ、それは、それは、そのです。」\n",
      "「ああ、それは、こんなことに、そのです。\n",
      "「ああ、まえ、それはいうないです。\n",
      "「こと、それが、それをとして、このです。\n",
      "「ああ、ませんなんだ。」\n",
      "「ああ、ますと、それには、いっているのです。\n",
      "「ああ、あい、あのことを、そのです。\n",
      "「そうない、いうないです。\n",
      "「ハハハ……、それはいうないです。\n",
      "「ああ、ますが、そのです。\n",
      "「ああ、それは、そのです。\n",
      "\n",
      "\n",
      "Epoch 7/60\n",
      "862/862 [==============================] - 121s 140ms/step - loss: 2.9555\n",
      "エポック:  6\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町とりの中に、そのほどのから、そのほどのうちが、そのなんというのです。\n",
      "「ああ、それが、このです。\n",
      "「ああ、それがら、いっとりの中に、その男に、その男の顔を見えて、その中で、その人の部下の、その人の部下の、その人の中に、その人の中に、その中に、そのから、その男のことを、このほどのかいうのです。\n",
      "「これが、これがらんな顔を見えているのです。\n",
      "「ああ、それが、このこのです。\n",
      "「これは、これがらんないのです。\n",
      "「ああ、それをして、このなんというのです。\n",
      "「ああ、それをして、このでもありません。\n",
      "「ああ、それをして、その人のうちが、このことをして、このなくのでした。\n",
      "「これは、これは、このほどのように、その男は、このほどのから、このあの人が、このことを、この中には、この中には、このなんというのです。\n",
      "「ああ、それをして、いくながら、あの人をとうして、そのうには、これからいくながら、これをしているので\n",
      "\n",
      "Epoch 8/60\n",
      "862/862 [==============================] - 119s 137ms/step - loss: 2.8511\n",
      "エポック:  7\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町というのは、その男のように、その中に、そのあいつに、それを見えるのです。\n",
      "「ああ、それは、あいまで、二十面相のことば、このまったく、その男の部下が、それからしているのです。\n",
      "「ああ、それが、それなことが、このまわりをしているのです。\n",
      "「おそろしい。」\n",
      "「え、それは、ああ、それが、それないのだ。」\n",
      "「ああ、それが、あいつは、その男のことば、その男が、このおまえさんのことば、このまえ、そのほうにういうするのです。\n",
      "「ああ、それが、これはいうのです。\n",
      "「ああ、それが、あいつは、この二十面相のあいつに、それから、あの人がわしいました。\n",
      "「ああ、それが、二十面相のことばをかけされています。\n",
      "「ああ、それが、ああ、それをしているんだ。」\n",
      "「ああ、ぼくは、これはなんだ。」\n",
      "「え、おこえます。」\n",
      "「ええ、あいついません。\n",
      "「ああ、それが、あいつは、そのうしいに、その男の中に、その中に、その男の部下に、その\n",
      "\n",
      "Epoch 9/60\n",
      "862/862 [==============================] - 125s 145ms/step - loss: 2.7434\n",
      "エポック:  8\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町とりのこと、おまわりさんが、この男の部下が、この中に、その中にはいっています。\n",
      "「ああ、そうです。」\n",
      "「え、それをというと、それを見えているのです。\n",
      "「ああ、さん、こんなことです。」\n",
      "「それが、このまで、このどうしているのです。\n",
      "「おい、どうです。」\n",
      "明智は、まるできないと、そのうちにちがいているのです。\n",
      "「ああ、あんだ。」\n",
      "と、このまえ、その人のことばかり、その男は、この中へといっているのです。\n",
      "「ああ、これが、こんなことをなっているのです。\n",
      "「おい、どうです。」\n",
      "明智は、まるできないて、そのうとうちょうないと、それには、この中に、その中へはいっているのです。\n",
      "「ああ、さん、こんなことを、このなんだから、この男が、いったりのように、それから、あのことを、この中へといているのです。\n",
      "「ああ、そうです。」\n",
      "明智は、まるでもいくないのです。\n",
      "「ああ、それがいうというのです。\n",
      "「ああ、そうです。\n",
      "\n",
      "Epoch 10/60\n",
      "862/862 [==============================] - 121s 141ms/step - loss: 2.6310\n",
      "エポック:  9\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町というの、二十面相の部下の、まわりのような、その男が、その男は、このあわしをして、いうしても、その男は、このなんだ。」\n",
      "明智は、さんところに、その男が、この男は、いったりのような、その男は、いったいのです。\n",
      "「ああ、さん、それは、あのうとも、もうものが、このなんだから、それには、もうのようなものです。\n",
      "「ああ、それは、これは、その男は、どんなことがあるからね。」\n",
      "「明智は、まったくのようなものです。\n",
      "「ああ、それは、まだ、その男は、この男は、その男は、まるでもなく、きみに、その男は、このなんだ。」\n",
      "明智は、まったくとして、いったいのです。\n",
      "「ああ、さんは、いったり、そのなんだから、この男が、このあることは、この男は、この男は、その男は、この人物の中に、その男があっているのです。\n",
      "「ああ、さん、そんなんだ。」\n",
      "明智は、まるでもあるんだ。」\n",
      "「ああ、さん、こんなことを、きみは、あの中には、その\n",
      "\n",
      "Epoch 11/60\n",
      "862/862 [==============================] - 118s 137ms/step - loss: 2.5414\n",
      "エポック:  10\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町というのは、その男は、いっぱりのぞいているのです。\n",
      "「おや、それがいっているのです。\n",
      "「ああ、それはねえ。」\n",
      "明智は、そのほかには、その男は、まったくなって、そのうちがいっているのです。\n",
      "「ああ、それが、こんなことをいっているのです。\n",
      "「おれ、きみは、これは、そのほかには、そのうちがいのことを、そのうえしいければ、いっぱり、そのうから、あのつは、このうちゃんというのです。\n",
      "「ああ、それはねえ。」\n",
      "明智は、いったりの名画を、ためて、そのうとうのようないうというのです。\n",
      "それは、その男は、このどこには、このうちゃんところがいっているのです。\n",
      "それは、またしても、その男はいったいです。\n",
      "それは、その男は、このうちがいくなっているのです。\n",
      "「おかえ、これは、これはなったから、これがられているのです。\n",
      "「これは、これは、これがらんないから、その男は、このおまえさんにちょうというのです。\n",
      "それは、その\n",
      "\n",
      "Epoch 12/60\n",
      "862/862 [==============================] - 117s 135ms/step - loss: 2.4443\n",
      "エポック:  11\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町とうに、一同の上に、その中に、おとりのことをとりのが、その男の手紙が、このことをいっているのです。\n",
      "「ああ、そうです。」\n",
      "「ああ、そうです。」\n",
      "「ああ、そうです。」\n",
      "「ああ、このじゃ、ぼくが二十面相のことばかりではありません。\n",
      "「ああ、それが、こんなことを、このおとりのという、その男の、このおとうさんのかくれがいませんでした。\n",
      "「この、おまえはなんだから、いっぱり、そのなから、いったい、その男が、いったいのです。\n",
      "「おや、おまえ、そのなんだから、あの人物を、その中には、このことをおりますと、その男の、二十面相の部下の、このどこに、そのじゃまちがいのかけでは、じつに、そのほかには、もののように、そのほかには、ものというのです。\n",
      "「おや、おまえ、このじょうぶんの用意がすると、そのじょうなんというのです。」\n",
      "「そうです。」\n",
      "明智は、いったりの、この建物の、いや、その男です。」\n",
      "「え、それがどうし\n",
      "\n",
      "Epoch 13/60\n",
      "862/862 [==============================] - 117s 136ms/step - loss: 2.3497\n",
      "エポック:  12\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町という、一枚の目にさがっていました。\n",
      "「おや、さすが、それがいるときのは、それがまるできない。」\n",
      "「ああ、さすが、あのよくなさんだから、それがら、あったのは、そのおまわりさんが、その男は、まるできないのです。\n",
      "「おい、さん、これがいるんだ。」\n",
      "「それがね、きみは、そのまえにちがっているのです。\n",
      "「おい、さん、これがいるんだ。」\n",
      "「ええ、ますます。」\n",
      "「おれ、きみは、これは、この事件のさいぜんの口の中に、その手をひきつけて、そのうちがちがいているのです。\n",
      "「おや、こんなことは、これしらべて、それを見ためて、その中には、このわしのにちがいないのです。\n",
      "「おい、あまりません。」\n",
      "「それが、それがまるんだような。」\n",
      "「え、そうだった。それは、まるできない。」\n",
      "「それが、それがいるんだ。」\n",
      "「ええ、そうです。」\n",
      "「ああ、またかくだれば、いったい、まるでしょう。\n",
      "「おい、きみは、まったく不可能なことで\n",
      "\n",
      "Epoch 14/60\n",
      "862/862 [==============================] - 117s 135ms/step - loss: 2.2385\n",
      "エポック:  13\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町という、一枚の名まえを見ていました。\n",
      "「この人というと、それを見つめているのです。\n",
      "「この人です。」\n",
      "明智は、またしても、その男は、おもうさんがいっているのです。\n",
      "「それです。ぼくは、いったい、ぼくは、その日の部下の部下が、まださんものを見えることがあるんでした。\n",
      "「ハハハ……、おどろいたことを、このましくして、その男は、どこにも見えるのです。\n",
      "「おや、おまえはないようないからね。」\n",
      "「それがね、きみは、このうちゃんの顔を見つめて、この中には、この男はいいことをいるのです。\n",
      "「明智君、あいつは、あの人には、もうとうとうのですからね。」\n",
      "「え、そうです。ぼくは、あのことは、このおまえさんのことを、ここにしているのです。\n",
      "「おまえ、こんなことをいるところでした。\n",
      "「ハハハ……、おどろい。」\n",
      "小林君は、そんなことを、このうちにちがいているのです。\n",
      "「このおと、こんなことをいっているのです。\n",
      "それ\n",
      "\n",
      "Epoch 15/60\n",
      "862/862 [==============================] - 117s 135ms/step - loss: 2.1412\n",
      "エポック:  14\n",
      "シード:  そのころ、東京中の町\n",
      "そのころ、東京中の町というの、三人の、まわりの人間の顔を見つめて、まるでも、この男は、このおまえさえがいたのです。\n",
      "「おや、あんだんです。」\n",
      "明智は、まるでもおかわしさんです。\n",
      "「ハハハ……、ご心配なさます。ああ、ああ、それがこうしているのです。\n",
      "「おや、おまえはなんだよ。」\n",
      "「それがね、あの方法は、このまたしてものびっしょうないのです。\n",
      "「おや、あんだんだ。」\n",
      "明智は、いったいどうして、そのうまでもなくなっています。\n",
      "「おや、それは、あまりにしかけると、そのつきのしいつの中に、その男が、まるでもなくなっています。\n",
      "ああ、それが、これはその人間が、このつきのようなものが、このまたして、その男は、まるでもなくなっています。\n",
      "ああ、それは、これがこの中に、その男をひきつけているのです。\n",
      "「おや、こんなことは、あのうかに、その日本部屋の中に、そのなから、いきなりの手に入り口をつきためるのです。\n",
      "「おや、あなたは、あ\n",
      "\n",
      "Epoch 16/60\n",
      "581/862 [===================>..........] - ETA: 39s - loss: 2.0323"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-52d1353f491d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history_lstm = model_lstm.fit(x, t,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     callbacks=[epock_end_callback])\n",
      "\u001b[0;32m/opt/anaconda3/envs/local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/envs/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model_lstm\n",
    "history_lstm = model_lstm.fit(x, t,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[epock_end_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次第に、乱歩のような文体の文章が生成されていくことが確認できますね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRUモデルの構築\n",
    "Kerasを使ってGRUを構築します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model_gru = Sequential()\n",
    "model_gru.add(GRU(n_mid, input_shape=(n_rnn, len(chars))))\n",
    "model_gru.add(Dense(len(chars), activation=\"softmax\"))\n",
    "model_gru.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
    "print(model_gru.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "構築したGRUを使って、学習を行います。  \n",
    "fit( )メソッドでコールバックの設定をし、エポック終了後に関数が呼ばれるようにします。  \n",
    "LSTMと同じく学習には数時間程度かかるので、時間のない方はエポック数を少なくして実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_gru\n",
    "history_gru = model_gru.fit(x, t,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[epock_end_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRUでも、乱歩のような文体の文章が生成されていくことが確認できますね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の推移\n",
    "誤差の推移を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_lstm = history_lstm.history['loss']\n",
    "loss_gru = history_gru.history['loss']\n",
    "\n",
    "plt.plot(np.arange(len(loss_lstm)), loss_lstm, label=\"LSTM\")\n",
    "plt.plot(np.arange(len(loss_gru)), loss_gru, label=\"GRU\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "両者ともに、誤差が収束していますね。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成された文章を比較\n",
    "LSTM、GRU、それぞれで生成された文章を比較してみましょう。\n",
    "\n",
    "#### LSTM\n",
    "Epoch 60/60  \n",
    "110313/110313 [==============================] - 126s 1ms/step - loss: 0.1493  \n",
    "エポック:  59  \n",
    "シード:  そのころ、東京中の町  \n",
    "そのころ、東京中の町という町、家という家では、ふたり以上の人が顔をあわせさえすれば、まるでお天気のあいさつでもするように、怪人「二十面相」のうわさばかりしているというのも、じつは、こわばかくで、ぼくをひっててやけるかもですね。その部屋にはあきません。おしてお目をとりだっしましたけれど、賊は、あいつは邸内が三人の前まになにのをつかれたというのです。  \n",
    "それでも、外見らめてあるというからだ。手がありません。  \n",
    "「二十面相のやつ、今夜ですよ。手紙のんのは、小林少年の苦心に、子どおりたんださい。このあばかな声ですから、そのじゃにともの見れています。もしかむこんわけは、何かしこそこしだ。こぎだから、ばかりタとしておね。ぼくはそうですね。あれは何かわらのことを、かけつけているのでしょうか。またかと大き賊の部下があのがわらをじて、じて、ゆっくりむずねばながってもたじつめて、庭園のことへはそうかさえしまいました。  \n",
    "「ああ、よかっ  \n",
    "\n",
    "#### GRU\n",
    "Epoch 60/60  \n",
    "110313/110313 [==============================] - 104s 942us/step - loss: 0.2000  \n",
    "エポック:  59  \n",
    "シード:  そのころ、東京中の町  \n",
    "そのころ、東京中の町という町、家という家では、ふたり以上の人が顔をあわせさ。すると、その下から黒々とした頭があらわれました。つぎには、おとうさんにちょっと会われてください。ぼくは少しやらくるようにしますと、電燈がよいつけて、主人の壮二君と、赤井寅三に、「二十面相」たいには、十分かしたというのかね。」  \n",
    "「ええ、おくびょうのようですけれど、なんだかそんな気がするのです。」  \n",
    "「だが、そんなことはないかなければよりませんでした。  \n",
    "「ほかのものならばかまわない。ダイヤなぞお金さえ出せば手にこぎってはたかぬかまりませんだ。それをしゃべりっていって、目的をはたしてしまったのですから、むりもないことです。  \n",
    "「いや、なんとも申しあげようもありません。二十面相がこれほどの腕まえとは知りませんでした。相手がですよ。それが二十面相の部下に会ったのか。いったい、どこで？どうして？」  \n",
    "さすがの警官はといって、やぶやから手もにもおわしてや  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回のケースでは、GRUで生成された文章の方が自然に見えますね。  \n",
    "興味のある方は、様々な条件をトライし、より自然な文章の生成にトライしてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "青空文庫の「銀河鉄道の夜」を読み込み、宮沢賢治風の文章をLSTM、もしくはGRUで自動生成してみましょう。  \n",
    "このノートブックと同じフォルダに、以下のファイルがあります。  \n",
    "gingatetsudono_yoru.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
