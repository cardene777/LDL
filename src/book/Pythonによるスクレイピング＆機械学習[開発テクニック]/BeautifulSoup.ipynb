{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39edd710",
   "metadata": {},
   "source": [
    "# BeatifulSoup\n",
    "\n",
    "- 手軽にHTMLやXMLから情報を抽出できる。\n",
    "- データのダウンロードはできないため、、データダウンロードには「urllib」を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5346093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = スクレイピングとは？\n",
      "p  = Webページを解析すること。\n",
      "p  = 任意の箇所を抽出すること。\n"
     ]
    }
   ],
   "source": [
    "# ライブラリを取り込む --- (※1)\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# 解析したいHTML --- (※2)\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1>スクレイピングとは？</h1>\n",
    "  <p>Webページを解析すること。</p>\n",
    "  <p>任意の箇所を抽出すること。</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する --- (※3)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 任意の部分を抽出する --- (※4)\n",
    "h1 = soup.html.body.h1\n",
    "p1 = soup.html.body.p\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "\n",
    "# 要素のテキストを表示する --- (※5)\n",
    "print(\"h1 = \" + h1.string)\n",
    "print(\"p  = \" + p1.string)\n",
    "print(\"p  = \" + p2.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38bf289",
   "metadata": {},
   "source": [
    "## 任意のidで要素を探す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f94d423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#title=スクレイピングとは？\n",
      "#body=Webページから任意のデータを抽出すること\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1 id=\"title\">スクレイピングとは？</h1>\n",
    "  <p id=\"body\">Webページから任意のデータを抽出すること</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する --- (※1)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# find()メソッドで取り出す --- (※2)\n",
    "# id指定で要素を取得\n",
    "title = soup.find(id=\"title\")\n",
    "body  = soup.find(id=\"body\")\n",
    "\n",
    "# テキスト部分を表示 \n",
    "print(\"#title=\" + title.string)\n",
    "print(\"#body=\"  + body.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83969d24",
   "metadata": {},
   "source": [
    "## 複数の要素を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "704fed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uta > http://uta.pw\n",
      "oto > http://oto.chu.jp\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <ul>\n",
    "    <li><a href=\"http://uta.pw\">uta</a></li>\n",
    "    <li><a href=\"http://oto.chu.jp\">oto</a></li>\n",
    "  </ul>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する --- (※1)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# findAll()メソッドで取り出す --- (※2)\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "# リンク一覧を表示 --- (※3)\n",
    "for a in links:\n",
    "    href = a.attrs['href']\n",
    "    text = a.string\n",
    "    print(text, \">\", href) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265893dd",
   "metadata": {},
   "source": [
    "## 郵便番号を検索してXMLを解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caab51ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "東京都 渋谷区 宇田川町\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "url = \"https://api.aoikujira.com/zip/xml/1500042\"\n",
    "\n",
    "# urlopen()でデータを取得 --- (※1)\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# BeautifulSoupで解析 --- (※2)\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 任意のデータを抽出 --- (※3)\n",
    "ken = soup.find(\"ken\").string\n",
    "shi = soup.find(\"shi\").string\n",
    "cho = soup.find(\"cho\").string\n",
    "print(ken, shi, cho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b3e46",
   "metadata": {},
   "source": [
    "## CSSのセレクターを指定して、要素を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a843d3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 = トルストイの名言\n",
      "li = 汝の心に教えよ、心に学ぶな\n",
      "li = 謙虚な人は誰からも好かれる。\n",
      "li = 強い人々は、いつも気取らない。\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# 解析対象となるHTML --- (※1)\n",
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "  <h1>トルストイの名言</h1>\n",
    "  <ul class=\"items\">\n",
    "    <li>汝の心に教えよ、心に学ぶな</li>\n",
    "    <li>謙虚な人は誰からも好かれる。</li>\n",
    "    <li>強い人々は、いつも気取らない。</li>\n",
    "  </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "# HTMLを解析する --- (※2)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 必要な部分をCSSクエリで取り出す\n",
    "# | タイトル部分を取得 --- (※3)\n",
    "h1 = soup.select_one(\"div#meigen > h1\").string   # CSSセレクターで要素を１つ取り出す。\n",
    "print(\"h1 =\", h1)\n",
    "\n",
    "# | リスト部分を取得 --- (※4)\n",
    "li_list = soup.select(\"div#meigen > ul.items > li\")   # CSSセレクターで複数要素を取り出しリスト型で返す。\n",
    "for li in li_list:\n",
    "    print(\"li =\", li.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865af87",
   "metadata": {},
   "source": [
    "## Yahooファイナンスから為替情報を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac1315b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usd/jpy= 108.100000\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "\n",
    "# HTMLを取得\n",
    "url = \"https://stocks.finance.yahoo.co.jp/stocks/detail/?code=usdjpy\"\n",
    "res = req.urlopen(url)\n",
    "\n",
    "# HTMLを解析\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "# 任意のデータを抽出 --- (※1)\n",
    "price = soup.select_one(\".stoksPrice\").string   # 為替レート取得\n",
    "print(\"usd/jpy=\", price)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
